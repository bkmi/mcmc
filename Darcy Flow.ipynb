{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Darcy Flow\n",
    "Including forward and inverse problem solver for 1D. Darcy Flow\n",
    "Darcy Flow\n",
    "\\begin{equation}\n",
    "    \\nabla \\cdot ( k(x) \\nabla u(x) ) = f(x)\n",
    "\\end{equation}\n",
    "\n",
    "Zero Dirichlet boundary conditions $u(0) = u(1) = 0$\n",
    "\n",
    "## Hints from Tim Sullivan\n",
    "\n",
    "Express $u$ as $u(x) = \\sum_{j = 1}^{n} u_{j} \\phi_{j}(x)$ with $\\phi_{j}(x) =$ piecewise linear tent function peaking at node $j$\n",
    "\n",
    "Solve $A(u_{1}, …, u_{n}) = b$ for the coefficients  \n",
    "\\begin{align}\n",
    "b_{j} &= \\int_{0}^{1} f(x) \\phi_{j}(x) d x \\\\\n",
    "A_{i j} &= \\int_{0}^{1} k(x) \\phi'_{i}(x) \\phi'_{j}(x) d x\n",
    "\\end{align}\n",
    "Google finite element method / Galerkin method for elliptic PDE \n",
    "\n",
    "I will give you e.g. (u(1/4), u(1/2), u(3/4)) and similarly for f, both corrupted by additive N(0, \\sigma^{2}) noise.\n",
    "Your challenge:  infer k\n",
    "\n",
    "--\n",
    "\n",
    "Modelling assumption:  $k(x) = exp( \\sum_{\\alpha = 0}^{A} k_{\\alpha} \\phi_{\\alpha}(x) )$\n",
    "\n",
    "--\n",
    "\n",
    "Try a Fourier basis. Note that u vanishes at the boundary, but that doesn't mean k does.\n",
    "\n",
    "Create the forward model. Solver works. Extend to imitation inverse model with likelihood, etc. Use this to solve his problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The Darcy Flow Problem\n",
    "\n",
    "We consider the Darcy Flow problem in one dimension with Dirichlet boundry conditions and a modeling assumption.\n",
    "\n",
    "\\begin{align}\n",
    "    k'(x) u'(x) + k(x) u''(x) &= f(x) \\\\\n",
    "    u(0) = u(1) &= 0 \\\\\n",
    "    exp( \\sum_{\\alpha = 0}^{A} k_{\\alpha} \\phi_{\\alpha}(x) ) &=  k(x)\n",
    "\\end{align}\n",
    "\n",
    "We put the equation into the weak form. $v(x)$ is a function which satisfies the boundary conditions.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\int_{0}^{1} f(x)v(x) \\ dx = \\int_{0}^{1} (k'(x) u'(x) v(x) + k(x) u''(x) v(x)) \\ dx\n",
    "\\end{equation}\n",
    "\n",
    "We can integrate by parts and apply our boundry conditions on the second R.H.S. term to arrive at the next equation.\n",
    "\n",
    "\\begin{align}\n",
    "    \\int_{0}^{1} f(x)v(x) \\ dx &= \\int_{0}^{1} k'(x) u'(x) v(x) \\ dx +\n",
    "                                  k(x) u'(x) v(x) |_{0}^{1} - \n",
    "                                  \\int_{0}^{1} k'(x) u'(x) v(x) \\ dx - \n",
    "                                  \\int_{0}^{1} k(x) u'(x) v'(x) \\ dx \\\\\n",
    "    \\int_{0}^{1} f(x)v(x) \\ dx &= - \\int_{0}^{1} k(x) u'(x) v'(x) \\ dx\n",
    "\\end{align}\n",
    "\n",
    "We choose the piecewise linear function $v_k$ for a discretization.\n",
    "\n",
    "\\begin{equation}\n",
    "v_{k}(x) = \n",
    "    \\begin{cases}\n",
    "        \\frac{x-x_{k-1}}{x_k-x_{k-1}} & \\text{if } x \\in [x_{k-1}, x_k] \\\\\n",
    "        \\frac{x_{k+1}-x}{x_{k+1}-x_k} & \\text{if } x \\in [x_{k}, x_{k+1}] \\\\\n",
    "        0 & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "If we expand $u(x)$ in a basis of tent functions on this discretization, we are left with the problem\n",
    "\n",
    "\\begin{equation}\n",
    "    A \\bf{u} = \\bf{b}\n",
    "\\end{equation}\n",
    "\n",
    "where $A_{ij} = - \\int_{0}^{1} k(x) v_{i}'(x) v_{j}'(x) \\ dx$ and $b_{j} = \\int_{0}^{1} f(x) v_{j} dx$. Note that this will be a sparse matrix due our use of tent functions. With our modeling assumption, only \n",
    "\n",
    "## Useful Links\n",
    "https://en.wikipedia.org/wiki/Finite_element_method  \n",
    "http://www.mathematik.uni-dortmund.de/~kuzmin/Transport.pdf  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Forward Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.integrate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid(nodes):\n",
    "    return np.linspace(0, 1, num=nodes)\n",
    "    \n",
    "def tent(x, k, grid):\n",
    "    def down(x):\n",
    "        return (grid[k+1] - x) / (grid[k+1] - grid[k])\n",
    "    def up(x):\n",
    "        return (x - grid[k-1]) / (grid[k] - grid[k-1])\n",
    "    if (k < 0) or (k > grid.size - 1):\n",
    "        raise ValueError('k was not in [0, grid.size - 1]')\n",
    "    elif k == 0:\n",
    "        if (grid[k] <= x) and (x <= grid[k+1]):\n",
    "            return down(x)\n",
    "        else:\n",
    "            return 0\n",
    "    elif k == grid.size - 1:\n",
    "        if (grid[k-1] <= x) and (x <= grid[k]):\n",
    "            return up(x)\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        if (grid[k-1] <= x) and (x <= grid[k]):\n",
    "            return up(x)\n",
    "        elif (grid[k] <= x) and (x <= grid[k+1]):\n",
    "            return down(x)\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "def κ(x, coefs, grid):\n",
    "    lo_bound = np.searchsorted(grid, x, 'left')\n",
    "    up_bound = np.searchsorted(grid, x, 'right')\n",
    "    \n",
    "    if (0 - 0.1 <= x) and (x < grid[1]):\n",
    "        return np.exp(sum([coefs[0] * tent(x, 0, grid), coefs[1] * tent(x, 1, grid)]))\n",
    "    elif (grid[-2] < x) and (x <= grid[-1] + 0.1):\n",
    "        return np.exp(sum([coefs[-2] * tent(x, grid.size - 2, grid), coefs[-1] * tent(x, grid.size - 1, grid)]))\n",
    "    else:\n",
    "        return np.exp(sum([coefs[k] * tent(x, k, grid) for k in [lo_bound, up_bound]]))\n",
    "    \n",
    "# def kappa(x, coefs, grid):\n",
    "#     return np.exp(sum([coefs[k] * tent(x, k, grid) for k in range(grid.size)]))\n",
    "\n",
    "def A(k, grid):\n",
    "    val = lambda x, y: scipy.integrate.quad(k, x, y, limit=100)[0]\n",
    "    lo_di = np.asarray([ val(grid[i-1], grid[i]  ) for i in range(2, grid.size - 1)])\n",
    "    di    = np.asarray([-val(grid[i-1], grid[i+1]) for i in range(1, grid.size - 1)])\n",
    "    up_di = np.asarray([ val(grid[i]  , grid[i+1]) for i in range(1, grid.size - 2)])\n",
    "    \n",
    "    return np.sum([np.diag(lo_di, -1), np.diag(di), np.diag(up_di, 1)], axis=0)\n",
    "\n",
    "def b(f, grid):\n",
    "    val = lambda x, y: scipy.integrate.quad(f, x, y)[0]\n",
    "    return np.asarray([-val(grid[i-1], grid[i+1]) for i in range(1, grid.size - 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = 5\n",
    "g = grid(nodes)\n",
    "plt.plot([κ(x, np.random.rand(nodes), g) for x in np.linspace(0, 1, num=100)])\n",
    "\n",
    "for i in range(nodes):\n",
    "    plt.plot([tent(x, i, g) for x in np.linspace(0, 1, num=100)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = 10\n",
    "pars = np.random.randn(nodes)\n",
    "g = grid(nodes)\n",
    "aa = A(lambda x: κ(x, pars, g), g)\n",
    "bb = b(lambda x: np.cos(x), g)\n",
    "\n",
    "np.linalg.solve(aa, bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Solver Using Tensorflow and Edward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import edward as ed\n",
    "import tensorflow as tf\n",
    "from edward.models import Empirical, Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu = Normal(loc=0.0, scale=1.0)\n",
    "x = Normal(loc=mu, scale=1.0, sample_shape=10)\n",
    "\n",
    "qmu = Empirical(tf.Variable(tf.zeros(500)))\n",
    "inference = ed.SGHMC({mu: qmu}, {x: np.zeros(10, dtype=np.float32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qmu_trace = qmu.params.eval()\n",
    "print(qmu_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Inverse Problem\n",
    "\n",
    "Given our Darcy Flow system, some coefficents of $u_{i}$ corrupted by additive noise $\\mathcal{N}(0, \\sigma^{2})$, and knowledge of $f(x)$, it is our job to infer the paramters $k_{\\alpha}$. \n",
    "\n",
    "This section referse to a case where:\n",
    "\n",
    "\\begin{equation}\n",
    "    - \\frac{d}{dx}(e^{u(x)} \\frac{dp}{dx}(x)) = f(x)\n",
    "\\end{equation}\n",
    "\n",
    "Data, In this case, we assume we have 3 data points:\n",
    "\n",
    "\\begin{align}\n",
    "    y &= [u(x_{1}), u(x_{4}), u(x_{9})] + \\mathcal{N}(0, \\sigma^{2})\n",
    "\\end{align}\n",
    "\n",
    "Centered gaussian prior on u:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{log prior density}(u) = - \\sum_{k=1}^{A} \\rho_k^2 (u_k)^2, \\rho_k \\sim \\frac{1}{k}\n",
    "\\end{equation}\n",
    "\n",
    "Write G for the u-to-y map, $G: \\mathbb{R}^K \\rightarrow \\mathbb{R}^3$. (3 because we have 3 data points.)\n",
    "\n",
    "\\begin{equation}\n",
    "    G(u) = [u(x_{1}), u(x_{4}), u(x_{9})]\n",
    "\\end{equation}\n",
    "\n",
    "Gaussian observerd noise:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{log likelihood}(u) = - \\frac{1}{2 \\sigma^2} ||G(u) - y||_{\\mathbb{R}^3, 2}^{2}\n",
    "\\end{equation}\n",
    "\n",
    "Log posterior to sample from (u|y)\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{log posterior}(u|y) = - \\frac{1}{2 \\sigma^2} ||G(u) - y||_{\\mathbb{R}^3, 2}^{2} + \\sum_{k=1}^{A} \\rho_k^2 u_k^2\n",
    "\\end{equation}\n",
    "\n",
    "The functions below use notation consistent with the forward solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Walk MCMC Function\n",
    "def metropolis_step(state, proposal_dist, target_dist):\n",
    "    proposed_state = state + proposal_dist.rvs()\n",
    "\n",
    "    acceptance_prob = min([0, target_dist(proposed_state) - target_dist(state)])\n",
    "\n",
    "    if acceptance_prob > 0 or np.log(np.random.rand()) <= acceptance_prob:\n",
    "        return proposed_state\n",
    "    else:\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def G_pre(k, f, grid):\n",
    "    \"\"\"(almost) Returns a vector of the forward solver given the vector of k_alphas.\"\"\"\n",
    "    aa = A(lambda x: κ(x, k, grid), grid)\n",
    "    bb = b(f, grid)\n",
    "\n",
    "    return aa, bb\n",
    "\n",
    "def spec_metropolis_step(state, data, data_inds, noise_sigma, prop_sigma, f, grid):\n",
    "    def GG(f, grid):\n",
    "        def gg(k):\n",
    "            aa, bb = G_pre(k, f, grid)\n",
    "            return np.linalg.solve(aa, bb)\n",
    "        return gg\n",
    "    \n",
    "    G = GG(f, grid)\n",
    "    \n",
    "    proposal_dist = scipy.stats.multivariate_normal(np.zeros_like(grid),\n",
    "                                                    np.eye(grid.shape[0]) * prop_sigma ** 2)\n",
    "    proposed_state = state + proposal_dist.rvs()\n",
    "    alpha = (np.linalg.norm(data - G(state)[data_inds]) ** 2 -\n",
    "             np.linalg.norm(data - G(proposed_state)[data_inds]) ** 2) / (2 * noise_sigma ** 2)\n",
    "    alpha += (np.linalg.norm(state) ** 2 - np.linalg.norm(proposed_state)) / (2 * prop_sigma ** 2)\n",
    "    \n",
    "    if alpha > 0 or np.log(np.random.rand()) <= alpha:\n",
    "        return proposed_state\n",
    "    else:\n",
    "        return state\n",
    "    \n",
    "\n",
    "def target(data, data_inds, prior_k, prior_sigma, noise_sigma, f, grid):\n",
    "    def logposterior(x):\n",
    "        aa, bb = G_pre(x, f, grid)\n",
    "        return -( \n",
    "            (1/(2 * noise_sigma**2) * (np.linalg.solve(aa, bb)[data_inds] - data) + \n",
    "             prior_k.norm / (2 * prior_sigma**2))\n",
    "        )\n",
    "    return logposterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MCMC Execution\n",
    "data = np.asarray([1,.5,0.2])\n",
    "data_inds = [0, 3, 7]\n",
    "f = lambda x: 1\n",
    "\n",
    "noise_sigma = 1\n",
    "prop_sigma = 1\n",
    "\n",
    "nodes = 10\n",
    "g = grid(nodes)\n",
    "states = [np.zeros_like(g)]\n",
    "steps = 100\n",
    "\n",
    "for i in range(steps):\n",
    "    states.append(spec_metropolis_step(states[-1], \n",
    "                                       data,\n",
    "                                       data_inds,\n",
    "                                       noise_sigma,\n",
    "                                       prop_sigma,\n",
    "                                       f,\n",
    "                                       g))\n",
    "    \n",
    "states = np.asarray(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(states)\n",
    "sns.pairplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
