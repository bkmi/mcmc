{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import distributions as dist\n",
    "\n",
    "import scipy.signal\n",
    "import scipy.stats\n",
    "\n",
    "from metropolis import acceptance_rate_per_step, conditional_prob, mala_step, lagk_ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Setup\n",
    "\n",
    "We have a target distribution and we will try to sample from it using Metropolis MCMC with various proposal distributions.\n",
    "\n",
    "Some useful links were found here:  \n",
    "http://www.mcmchandbook.net/HandbookChapter1.pdf  \n",
    "https://theclevermachine.wordpress.com/2012/11/19/a-gentle-introduction-to-markov-chain-monte-carlo-mcmc/\n",
    "\n",
    "\n",
    "Information on lag-k autocorrelation:\n",
    "http://www.itl.nist.gov/div898/handbook/eda/section3/eda35c.htm\n",
    "\n",
    "Given measurements, $Y_1, Y_2, ..., Y_N$ at time $X_1, X_2, ..., X_N$, the lag k autocorrelation function is defined as\n",
    "\\begin{equation}\n",
    "    r_k = \\frac{\\sum_{i=1}^{N-k}(Y_{i} - \\bar{Y})(Y_{i+k} - \\bar{Y})}{\\sum_{i=1}^{N}(Y_{i} - \\bar{Y})^{2}}\n",
    "\\end{equation}\n",
    "\n",
    "Check out:  \n",
    "adaptaive metropolis  \n",
    "rwm N(o,simga I) find simga  \n",
    "deterministic schedule is unbiased, adaptive is bias  \n",
    "autograd <- differentiation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select bimodal\n",
    "if False:\n",
    "    mean1 = [2, 0]\n",
    "    cov1 = [[1, 0], [0, 1]]\n",
    "\n",
    "    mean2 = [-2, 0]\n",
    "    cov2 = [[1, 0], [0, 1]]\n",
    "    \n",
    "    rv = dist.bimodal_dist(mean1, mean2, cov1, cov2)\n",
    "    \n",
    "    proposal_dist = scipy.stats.multivariate_normal([0,0], np.asarray([[1,0],[0,1]]))\n",
    "    \n",
    "# Select parabolic gaussian\n",
    "if False:\n",
    "    mean = [0, 0]\n",
    "    cov = [[1, 0], [0, 10]]\n",
    "\n",
    "    rv = dist.parabolic_gaussian(mean, cov, warp=0.9)\n",
    "    \n",
    "    proposal_dist = scipy.stats.multivariate_normal([0,0], np.asarray([[1,0],[0,1]]))\n",
    "\n",
    "# Select streched gaussian\n",
    "if True:\n",
    "    mean = [0, 0]\n",
    "    cov = [[1, 0], [0, 100]]\n",
    "    \n",
    "    rv = dist.stretched_normal(mean, cov)\n",
    "    \n",
    "    proposal_dist = [scipy.stats.multivariate_normal([0,0], np.asarray([[1,0],[0,.1]])), \n",
    "                    scipy.stats.multivariate_normal([0,0], np.asarray([[.1,0],[0,10]]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(111)\n",
    "ax1.plot(*rv.rvs(1000).T, marker='o', linestyle='None')\n",
    "ax1.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "x, y = np.mgrid[-10:10:.1,\n",
    "                -10:10:.1]\n",
    "pos = np.dstack((x, y))\n",
    "\n",
    "# pdf\n",
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(111)\n",
    "ax2.contourf(x, y, rv.pdf(pos))\n",
    "plt.show()\n",
    "\n",
    "# logpdf\n",
    "fig3 = plt.figure()\n",
    "ax3 = fig3.add_subplot(111)\n",
    "ax3.contourf(x, y, rv.logpdf(pos))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Walk MCMC Function\n",
    "def metropolis_step(state, proposal_dist, target_dist, v=False, log=False):\n",
    "    if not isinstance(proposal_dist, list) and callable(proposal_dist.rvs):\n",
    "        proposed_state = state + proposal_dist.rvs()\n",
    "    elif isinstance(proposal_dist, list) and callable(proposal_dist[0].rvs):\n",
    "        pick = np.random.choice(len(proposal_dist))\n",
    "        proposed_state = state + proposal_dist[pick].rvs()\n",
    "    \n",
    "    # Note that this is a metropolis algorithm because:\n",
    "    # scipy.stats.multivariate_normal(state, covar).pdf(proposed_state) == \n",
    "    # scipy.stats.multivariate_normal(proposed_state, covar).pdf(state)\n",
    "    \n",
    "    if not log:\n",
    "        acceptance_prob = min([1, target_dist.pdf(proposed_state)/target_dist.pdf(state)])\n",
    "\n",
    "        if v:\n",
    "            print(state, proposed_state, target_dist.pdf(proposed_state)/target_dist.pdf(state))\n",
    "\n",
    "        if np.random.rand() <= acceptance_prob:\n",
    "            return proposed_state\n",
    "        else:\n",
    "            return state\n",
    "    else:\n",
    "        acceptance_prob = min([0, target_dist.logpdf(proposed_state) - target_dist.logpdf(state)])\n",
    "\n",
    "        if v:\n",
    "            print(state, proposed_state, target_dist.logpdf(proposed_state) - target_dist.logpdf(state))\n",
    "\n",
    "        if np.log(np.random.rand()) <= acceptance_prob:\n",
    "            return proposed_state\n",
    "        else:\n",
    "            return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCMC Execution\n",
    "states = [np.array([0,0])]\n",
    "steps = 1000\n",
    "\n",
    "for i in range(steps):\n",
    "    states.append(metropolis_step(states[-1], proposal_dist, rv, v=False, log=True))\n",
    "    \n",
    "states = np.asarray(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceptance rate plot\n",
    "acps = acceptance_rate_per_step(states)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(steps ), acps)\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Acceptance Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample and trace plots\n",
    "df = pd.DataFrame(states, columns=[\"x\", \"y\"])\n",
    "\n",
    "plt.figure(1, figsize=(8,8))\n",
    "plt.subplot(121)\n",
    "plt.scatter(df.x, df.y, c=rv.pdf(states))\n",
    "plt.axis('equal')\n",
    "plt.title('Samples plot')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(np.arange(states.shape[0]), df.x)\n",
    "plt.title('Trace plot')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('x')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(np.arange(states.shape[0]), df.y)\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def lag_line(sequence, k):\n",
    "#     plot_ac = []\n",
    "#     variance = np.sum(np.dot(sequence[..., 0] - np.mean(sequence[..., 0], axis=0), (sequence[..., 0] - np.mean(sequence[..., 0], axis=0)).T))\n",
    "\n",
    "#     for i in range(len(sequence)):\n",
    "#         if i < k:\n",
    "#             pass\n",
    "#         else:\n",
    "#             plot_ac.append([i, lagk_ac(sequence[:i], k, v=False, variance=variance)])\n",
    "#     return np.asarray(plot_ac)\n",
    "\n",
    "# lag1 = lag_line(states, 1)\n",
    "# lag5 = lag_line(states, 5)\n",
    "# lag10 = lag_line(states, 10)\n",
    "# lag50 = lag_line(states, 50)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.plot(lag1[:,0], lag1[:,1])\n",
    "# ax.plot(lag5[:,0], lag5[:,1])\n",
    "# ax.plot(lag10[:,0], lag10[:,1])\n",
    "# ax.plot(lag50[:,0], lag50[:,1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "y = scipy.signal.correlate(states[:,0], states[:,0])\n",
    "x = range(-int(len(y)/2), int(len(y)/2) + 1)\n",
    "\n",
    "plt.plot(x[int(len(x)/2)+1:], y[int(len(x)/2)+1:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr(x):\n",
    "    \"\"\"\n",
    "    Computes the ( normalised) auto-correlation function of a\n",
    "    one dimensional sequence of numbers.\n",
    "    \n",
    "    Utilises the numpy correlate function that is based on an efficient\n",
    "    convolution implementation.\n",
    "    \n",
    "    Inputs:\n",
    "    x - one dimensional numpy array\n",
    "    \n",
    "    Outputs:\n",
    "    Vector of autocorrelation values for a lag from zero to max possible\n",
    "    \"\"\"\n",
    "    \n",
    "    # normalise, compute norm\n",
    "    xunbiased = x - np.mean(x)\n",
    "    xnorm = np.sum(xunbiased ** 2)\n",
    "    \n",
    "    # convolve with itself\n",
    "    acor = np.correlate(xunbiased, xunbiased, mode='same')\n",
    "    \n",
    "    # use only second half, normalise\n",
    "    acor = acor[int(len(acor) / 2):] / xnorm\n",
    "    \n",
    "    return acor\n",
    "\n",
    "\n",
    "y = autocorr(states[:,0])\n",
    "\n",
    "plt.plot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
